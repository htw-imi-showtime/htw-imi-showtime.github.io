<!doctype html><html lang=de dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>IMI Showtime</title><link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel=stylesheet><link href=/dist/css/main.css rel=stylesheet></head><body><header><h1><img src=https://htw-imi-showtime.github.io//images/imi.svg alt="IMI Logo">
<a href=https://htw-imi-showtime.github.io/>IMI Showtime</a></h1><nav><span>Sommersemester 2020 &#9662;</span><ul><li><a href=https://htw-imi-showtime.github.io/ss20/>Sommersemester 2020</a></li></ul></nav></header><main><a href=/ss20/>&larr; Sommersemester 2020</a><div><h1>M3 phoion</h1><section class=links><a href=https://github.com/m-glock/Deep-Learning-Image-Organization><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path d="M278.9 511.5l-61-17.7c-6.4-1.8-10-8.5-8.2-14.9L346.2 8.7c1.8-6.4 8.5-10 14.9-8.2l61 17.7c6.4 1.8 10 8.5 8.2 14.9L293.8 503.3c-1.9 6.4-8.5 10.1-14.9 8.2zm-114-112.2 43.5-46.4c4.6-4.9 4.3-12.7-.8-17.2L117 256l90.6-79.7c5.1-4.5 5.5-12.3.8-17.2l-43.5-46.4c-4.5-4.8-12.1-5.1-17-.5L3.8 247.2c-5.1 4.7-5.1 12.8.0 17.5l144.1 135.1c4.9 4.6 12.5 4.4 17-.5zm327.2.6 144.1-135.1c5.1-4.7 5.1-12.8.0-17.5L492.1 112.1c-4.8-4.5-12.4-4.3-17 .5L431.6 159c-4.6 4.9-4.3 12.7.8 17.2L523 256l-90.6 79.7c-5.1 4.5-5.5 12.3-.8 17.2l43.5 46.4c4.5 4.9 12.1 5.1 17 .6z"/></svg>Source Code</a></section></div><figure><img src=/ss20/master/m3-mobile-image-organization/header.PNG alt=header width=1000></figure><h4 id=projektbetreuung>Projektbetreuung</h4><p>Konstantin Schall</p><h4 id=teilnehmende>Teilnehmende</h4><ul><li>Leonid Barsht</li><li>Mareike Glock</li><li>Florian Schlüter</li><li>Daniel Wunderlich</li></ul><h2 id=beschreibung>Beschreibung</h2><p>Egal ob Selfie, Momentaufnahme oder Landschaftsfoto ein zufriedenstellendes Ergebnis gelingt nur selten beim ersten Versuch mit der Handykamera. Folglich enthalten viele Bildsammlungen auf mobilen Geräten eine Vielzahl von sehr ähnlichen Bildern, die nur selten aussortiert werden.</p><p>Das Ziel des Projekts ist es eine App zu entwickeln, die das Aufräumen und Organisieren von Handyfotos vereinfacht. Mit der App können ähnliche, zu helle oder zu dunkle und verschwommene Bilder ausfindig gemacht werden. Diese können direkt miteinander verglichen werden, um zu entscheiden, welche der User behalten möchte und welche nicht. Außerdem ermöglichen Tags und Metadaten der Bilder, diese einfach zu gruppieren und danach zu suchen.</p><h3 id=duplikaten-und-ähnlichen-bildern>Duplikaten und ähnlichen Bildern</h3><p>Für das Finden von Duplikaten und ähnlichen Bildern haben wir ein Tensorflow Model benutzt. Für jedes Bild in der Handygalerie wird zu Beginn durch das Model ein Featurevektor berechnet und lokal in einer Datenbank abgespeichert. Hat der Nutzer sich dazu entschieden, in seinem Handy nach ähnlichen Bildern zu suchen, wird die Distanz zwischen diesen Featurevektoren genutzt, um zu bestimmen, welche Bilder einander ähnlich sind. Das gleiche passiert bei der Suche nach zu dunklen/hellen und verschwommenen Bildern. Diese werden untereinander auch noch einmal auf ihre Ähnlichkeit vergleichen und entsprechend in kleine Gruppen ähnlicher Bilder eingeteilt.</p><h3 id=bildern-mit-schlechter-qualität>Bildern mit schlechter Qualität</h3><p>„Schlechte Qualität“ kann vieles bedeuten, wir haben uns aber auf zu dunkle/helle oder verschwommene Bildern fokussiert. Diese werden gesucht/bestimmt, sobald der Nutzer den Cleanup View öffnet, die entsprechenden Optionen auswählt und auf „Scan starten“ klickt. Verschwommene Bilder werden mit einem weiteren Tensorflow Model erkannt, welches zwischen Kamera- und Bewegungsunschärfe unterscheiden kann. Zu helle/dunkle Bilder werden mithilfe eines Algorithmus erkannt, der die Anzahl dunkler bzw. heller Pixel in einem Bild zählt und ab einem definierten Schwellenwert entschiedet, ob das Bild in eine der beiden Kategorien fällt.</p><h3 id=klassifizierung>Klassifizierung</h3><p>Der Nutzer hat die Möglichkeit sein Bilder sowohl mit individuellen Tags zu beschreiben, als auch die automatische Klassifizierung durch ein neuronales Netzwerk zu nutzen.
Die Klassifikation der Bilder findet anhand der wahrscheinlichsten Bildinhalten statt . Von 1001 möglichen Kategorien (Hunde, Katzen, Blumen, etc) werden die die mit den höchsten Werten innerhalb des neuronalen Netzes als Tags vorgeschlagen.</p><h3 id=gruppierung-und-sortierung>Gruppierung und Sortierung</h3><p>Durch Gruppierung und Sortierung der Bildersamlung nach Datum, Ort oder Kategorie, wird das Finden von bestimmten Bildern vereinfacht.</p><h2 id=technologien>Technologien</h2><h3 id=tensorflow>TensorFlow</h3><h3 id=was-ist-tensorflow>Was ist TensorFlow?</h3><p>TensorFlow ist eine Open-Source Machine Learning Bibliothek von Google, welche unter anderem für Produkte wie Googles Maps, Gmail, Spracherkennung und die Suche selbst verwendet wird.</p><p>Mit dieser Bibliothek ist es möglich Modelle zu bauen und zu trainieren, welche unter anderem zur Erkennung von Bildern und Audios verwendet werden können.
Hierbei werden verschiedene Sprachen wie Java, Python und C++ unterstützt.</p><p>TensorFlow arbeitet mit einem Graphen in welchem die Kanten sogenannte Tensoren sind, die n-dimensionale Datenarrays darstellen. Die Knoten wiederum beschreiben mathematische Operationen, die Inputs von den Kanten erhalten und Outputs zurückgeben. Die Berechnungen passieren hierbei für die bestmögliche Performance in C++.</p><p>Ein Vorteil von TensorFlow ist das einfache Erstellen von Modellen, die entweder mit wenigen Zeilen Python-Code, oder auch mit hierfür dedizierten Plattformen mit GUIs wie Microsofts Azure oder Googles Teachable Machine, umgesetzt werden können. Wir arbeiteten mit Teachable Machine. Außerdem hat TensorFlow eine große Community mit vielen bereits verwendbaren Modellen.</p><p>Für die Definition eigener Modelle wird zudem eine Abstraktion geboten, die kein manuelles Verbinden von Inputs und Outputs mehr erfordert und bereits existierende Algorithmen zum Arbeiten bietet.</p><h3 id=tensorflow-lite>TensorFlow Lite</h3><p>Da wir eine mobile Applikation entwickeln, verwenden wir TensorFlow Lite. Dieses konvertiert existierende Modelle in optimierte, effizientere Versionen unter Berücksichtigung der geringeren Performance und des geringen Speicherplatzes von Smartphones.
Lite kann ferner auch mit IoT-Geräten und Raspberry Pis verwendet werden.</p><p>Der größte Vorteil für uns ist, dass Lite lokal und somit offline funktionieren kann. Alternativ kann bei Bedarf jedoch auch mit Modellen in der Cloud gearbeitet werden.</p><h3 id=verwendung-in-der-app>Verwendung in der App</h3><p>Für unser Projekt haben wir ein vortrainiertes Mobilenet-Modell verwendet, welches in übergebenen Bildern Objekte aus 1001 Kategorien erkennen und diesen einen Faktor zuweisen kann. Dieses Modell haben wir manuell erweitert, damit dieses zusätzlich sogenannte Feature Vektoren zurückgibt. Dies ermöglicht und das Vergleichen verschiedener Bilder für unsere Ähnlichkeitssuche.</p><p>Außerdem trainierten wir selbst ein Modell mit einem Set an verschwommenen und nicht verschwommenen Bildern, welches parallel zum ersten Modell für das Klassifizieren von Bildern verwendet wird.</p><p>Die Modelle werden hierbei mit der App installiert und sind folglich offline verwendbar.</p><h3 id=xamarin>Xamarin</h3><p>Xamarin.Forms ist ein open-source Framework zum Erstellen von Android, iOS und Windows Apps.</p><p>Eine gemeinsame Codebasis aus in XAML geschriebener UI und dahinter liegendem C# Code für alle Plattformen ermöglicht es das Backend und Frontend einheitlich zu erstellen.
Xamarin übersetzt diesen Code und rendert die UI Elemente, um sie auf allen Plattformen nativ darstellen zu können.</p><p>Funktionalitäten, die nicht plattformübergreifend implementierbar sind, wie z.B. low-level touch Erkennung oder das Auslesen der internen Daten, können auch speziell für die einzelnen Plattformen programmiert werden.
Zusätzlich zu einer großen Sammlung von vorhandenen Libraries gibt es außerdem die Möglichkeit bestehende Java, Swift und C++ Libraries einzubinden.</p><h2 id=herausforderungen>Herausforderungen</h2><h3 id=wie-vergleicht-man-bilder-in-der-app>Wie vergleicht man Bilder in der App?</h3><p>Eines der wichtigsten Features unsere App ist das Vergleichen von ähnlichen Bildern, um besser entscheiden zu können, welche man behält und welche gelöscht werden können. Jedoch war die genaue Umsetzung dieses Features alles andere als einfach. Wir habe nach einer Möglichkeit gesucht, immer jeweils zwei Bilder direkt miteinander zu vergleichen und trotzdem jedes Bild möglichst groß anzeigen zu können.</p><p>Das Ergebnis ist, dass der Nutzer sich ein Hauptbild aus einem Set von ähnlichen Bildern aussuchen und die restlichen Bilder des Sets Schritt für Schritt mit diesem vergleichen kann. Durch das Swipen nach links oder rechts kann man zwischen den Bildern aus dem Set wechseln. Hält man das angezeigt Bild gedrückt, erscheint das Hauptbild; lässt man los, sieht man wieder das aktuelle Bild aus dem Set der ähnlichen Bilder. Dies ermöglicht einen direkten Vergleich zweier Bilder, um sich zu entscheiden, welches gelöscht werden soll. Dies geschieht durch das Swipen nach unten.</p><h3 id=einbindung-von-tensorflowlite-in-xamarin>Einbindung von TensorflowLite in Xamarin</h3><p>Zu Beginn haben wir uns gemeinsam dazu entschieden, für unsere App Microsofts Xamarin zu benutzen. Erste Recherchen hatte auch ergeben, dass Xamarin über eine TensorflowLite Library für mobile Applikationen verfügen.</p><p>Es stellte sich jedoch heraus, dass die Library nur für Android Apps nutzbar war und es keine TensorflowLite Library für iOS in Xamarin gab. Hinzu kam noch, dass die TFLite Library für Android in Xamarin nur für Bildklassifizierungsmodelle aus Custom Vision (der Machine Learning platform von Microsoft) vernünftige Ergebnisse zu liefern schien, aber nicht bei Modellen von der offiziellen Tensorflow Webseite .</p><p>Nach weiteren Recherchen haben wir es schließlich geschafft, die originale Tensorflow Lite Library für Android (in Java geschrieben) über ein <a href=https://docs.microsoft.com/de-de/xamarin/android/platform/binding-java-library/>Binding Project</a> in unsere App einzubinden. Das Binding Project umschließt die Java Library mit C# Wrappern für jede Methode, sodass diese innerhalb eines C# Projekts aufgerufen werden können. Die daraus entstehende .dll Datei wird als externe Library in unsere App eingebunden.</p><h2 id=weitere-inhalte>Weitere Inhalte</h2><ul><li><a href=gallery>App Gallery</a></li></ul></main><footer><section><span>Licensed under <a href=https://creativecommons.org/licenses/by-nc/3.0/de/deed.en_US>CC BY-NC 3.0 DE</a></span></section><section><a href=https://htw-imi-showtime.github.io/datenschutzerkl%C3%A4rung/>Datenschutzerklärung</a>
<a href=https://htw-imi-showtime.github.io/impressum/>Impressum</a></section></footer><script src=/dist/js/menu.js type=text/javascript></script></body></html>